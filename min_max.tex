\subsection{Min-Max Variants}

Let $f$ and $g$ denote two functions that get as an input a single integer $i = 0, 1, \ldots$. The \emph{Min-Max} and \emph{Arg-Min-Max} functions over $f$ and $g$ and an integer $j$, denoted by \emph{MM} and \emph{ARG-MM}, respectively, are defined as follows:

\begin{align}
	\text{MM}(f, g, j) &= \min_{0 \leq i < j} \max \left\{f(i), g(i)\right\}, 
	\label{eq:MM} \\
	\text{ARG-MM}(f, g, j) &= \argmin_{0 \leq i < j} \max \left\{f(i), g(i)\right\}.
	\label{eq:ARG-MM}
\end{align}


In this section we consider the problem of computing MM$(f, g_j, j)$ and ARG-MM$(f, g_j, j)$ for a fixed function $f$ and a series of functions $g_1, g_2, \ldots, g_n$, where the latter series adhere to two different sets of restrictions. 

[TODO: find better terms than type 1 and 2.]

\subsubsection{Type 1}

A series of functions $g_1, g_2, \ldots, g_n$ is of \emph{Type 1} if every function $g_j$ in the series is monotonously non-increasing, and for every two consecutive functions $g_{j-1}$ and $g_j$ and for every integer $0 \leq i < j-1$, $g_j(i) \geq g_{j-1}(i)$.

In what follows, assume a function $f$ and a Type 1 function series $g_1, g_2, \ldots, g_n$ are given.
Say that an index $0 \leq i < j$ is \emph{dominant} with respect to $j$ and denote $i \in D_j$, if for every $0 \leq i' < i$ it holds that $\max\left\{f(i), g_j(i)\right\} \leq \max\left\{f(i'), g_j(i')\right\}$. Note there may be multiple such dominant indices, and denote by $i^\star_j$ the maximal dominant index with respect to $j$. Observe that for every $0 \leq i < j$, $\max\left\{f(i^\star_j), g_j(i^\star_j)\right\} \leq \max\left\{f(i), g_j(i)\right\}$. Therefore, 

\begin{align}
	\text{MM}(f, g_j, j) &= \max\left\{f(i^\star_j), g(i^\star_j)\right\},
	\label{eq:MM1} \\
	\text{ARG-MM}(f, g_j, j) &= i^\star_j.
	\label{eq:ARG-MM1} 
\end{align}

We next show how can indices of the form $i^\star_j$ can be efficiently computed, given the preceding indices $i^\star_{j-1}$.

\begin{claim}
	\label{clm:dominance_a}
	$i \in D_j$ if and only if $f(i) \leq \max\left\{f(i'), g_j(i')\right\}$ for every $0 \leq i' < i$.
\end{claim}

\begin{proof}
	Let $i$ and $i'$ be indices such that $0 \leq i' < i$.
	Since $g_j$ is monotonously non-increasing, $g_j(i) \leq g_j(i') \leq \max\left\{f(i'), g_j(i')\right\}$. Therefore, $\max\left\{f(i), g_j(i)\right\} \leq \max\left\{f(i'), g_j(i')\right\}$ if and only if $f(i) \leq \max\left\{f(i'), g_j(i')\right\}$. By the definition of dominance, $i \in D_j$ if and only if the latter inequality holds for every $0 \leq i' < i$.
\end{proof}

\begin{claim}
	\label{clm:dominance_b}
	If $i \in D_{j-1}$ then $i \in D_j$.
\end{claim}

\begin{proof}
	Let $i$ be an index such that $i \in D_{j-1}$. Due to Claim~\ref{clm:dominance_a}, to prove the claim we only need to show that $f(i) \leq \max\left\{f(i'), g_j(i')\right\}$ for every $0 \leq i' < i$.
	Let $i'$ be any such index.
	If $f(i) \leq f(i')$, it immediately follows that $f(i) \leq \max\left\{f(i'), g_j(i')\right\}$.
	Otherwise  $f(i) > f(i')$. Since $i \in D_{j-1}$ we get that $f(i) \leq \max\left\{f(i'), g_{j-1}(i)\right\}$. This means that $f(i) \leq g_{j-1}(i') \stackrel{\text{Type 1}}{\leq} g_j(i')$, and in particular $f(i) \leq \max\left\{f(i'), g_j(i')\right\}$.
\end{proof}


Note that if $i \in D_j$ and $i = j-1$, it must be that $i = i^\star_j$. Otherwise, Claim~\ref{clm:dominance_next} below describes a property that allows, given \emph{some} dominant index $i$ with respect to $j$, to traverse an increasing sequence of dominant indices in order to identify $i^\star_j$ without considering non-dominant indices. More importantly, it provides a condition that allows to identify $i^\star_j$ once it has been reached.

\begin{claim}
	\label{clm:dominance_next}
	Let $i < j-1$ be an index such that $i \in D_j$, and let $k = \argmin_{i < i' < j} f(i')$. 
	If $f(k) > \max\left\{f(i), g_j(i)\right\}$ then $i = i^\star_j$, and otherwise $k \in D_j$.
\end{claim}

\begin{proof}
	For the case when $f(k) > \max\left\{f(i), g_j(i)\right\}$, it follows from the selection of $k$ that for every $i < i' < j$ it holds that $\max\left\{f(i), g_j(i)\right\} < f(k) \leq f(i') \leq \max\left\{f(i'), g_j(i')\right\}$, and so $i = i^\star_j$.
	
	For the case when $f(k) \leq \max\left\{f(i), g_j(i)\right\}$, we need to show that $k \in D_j$. From Claim~\ref{clm:dominance_a}, it is sufficient to show that $f(k) \leq \max\left\{f(i'), g_j(i')\right\}$ for every $0 \leq i' < k$. For $i' \leq i$ this follows immediately from the fact that $i$ is dominant respect to $j$. For $i < i' < k$, the inequality holds since $f(k) \leq f(i') \leq \max\left\{f(i'), g_j(i')\right\}$.
\end{proof}

In order to utilize Claim~\ref{clm:dominance_next} for the efficient identification of $i^\star_j$, there is also a need to be able to efficiently find an index $k$ such that $k = \argmin_{i < i' < j} f(i')$. This is known as the Range Minimum Query problem [TODO: add citations], for which there are efficient implementations that allow, after linear preprocessing time, to execute each query in a constant time. In our case, as will be shown later, the function $f$ is not available in its entirety for preprocessing - values of the form $f(j)$ will be sequentially computed throughout the algorithm's run, while range minimum queries over $f$ will have to be performed prior to the full computation of $f$. Nevertheless the series of queries executed throughout the computation has the property of having monotonously increasing endpoints (that is, for every pair of endpoints $(i, j)$ and $(i', j')$ in two consecutive queries, it holds that $i \leq i'$ and $j \leq j'$). This is known as the \emph{Sliding RMQ} problem, for which there is a significantly simpler solution than those for general RMQ~\cite{lee2007simple}. Besides its simplicity, this solution does not require the entire array over which the queries are performed to be given prior to the series of queries. It maintains a data structure that allows the sequential addition of elements at the end of the array, and to execute queries given that their endpoints are within the current array length. In this paper, we will denote such a structure by the letter $R$. The procedure ARG-MIN$(R, i, j)$ returns an index $i < k < j$ that minimizes $f(k)$ when $i < j-1$, or NULL when $i \geq j-1$. We will write $R \sim R_{i, j}$ to indicate the internal state of $R$ allows to execute a query ARG-MIN$(R, i', j')$ such that $i' \geq i$ and $j' \geq j$, provided that $f(i'+1), f(i'+2), \ldots, f(j'-1)$ are available to the ARG-MIN procedure.
While some queries might take more than a constant time for their execution, the overall running time for executing $m$ queries over an array whose final length is $n$, is $O(m+n)$. 
[TODO: consider adding an appendix with implementation details.] Algorithm~\ref{algo:maxDominant} computes $i^\star_j$, given some $i \in D_j$ (later we use $i^\star_{j-1}$ as the initial index when applying this procedure) and the data structure $R$.

%\begin{algorithm}
%	\Precondition{$i$ is dominant with respect to $j$, and $D ~ D_{i, j}$ for some $i' \leq i$ and $j' \leq j$}
%	\If{$i < j-1$}{
%		$k \gets \text{GetMin}(D, i, j)$\;
%		\LoopInv{$i < j-1$, $i$ is dominant with respect to $j$, $k = \argmin_{i < i' < j} f(i')$, and $D = D_{i, j}$ }
%		\While{$f(k) \leq \max\left\{f(i), g_j(i)\right\}$}{
%			\Condition{$k$ is dominant with respect to $j$ and $k > i$}
%			$i \gets k$\;
%			\If{$i = j-1$}{\Break}
%			$k \gets \text{GetMin}(D, i, j)$\;
%		}
%	}
%	\Postcondition{$i = i^\star_j$}
%	\Return{$i$}\;
%	\caption{MaxDominant$(f, g_j, D, i, j)$}
%	\label{algo:maxDominant}
%\end{algorithm}

\begin{algorithm}
	\Precondition{$i \in D_j$, and $R \sim R_{i, j}$}
	$k \gets \text{GetMin}(R, i, j)$\;
	\LoopInv{$i \in D_j$, $k = \argmin_{i < i' < j} f(i')$ (or NULL if $i \geq j-1$), and $R \sim R_{i, j}$ }
	\While{$i < j-1$ \And $f(k) \leq \max\left\{f(i), g_j(i)\right\}$}{
		\Condition{$k \in D_j$ and $k > i$}
		$i \gets k$\;
		$k \gets \text{GetMin}(R, i, j)$\;
	}
	\Postcondition{$i = i^\star_j$, and $R \sim R_{i^\star_j, j}$}
	\Return{$i$}\;
	\caption{MaxDominant$(f, g_j, R, i, j)$}
	\label{algo:maxDominant}
\end{algorithm}


\paragraph{Time complexity.}
Consider the sequential execution of Algorithm~\ref{algo:maxDominant} in order to compute $i^\star_j$ for $j = 1, 2, \ldots, n$. For each such index $j$, $i^\star_j$ is set to be the result of MaxDominant$(f, g_j, R^{j-1}, i^\star_{j-1}, j)$, where $R^{j-1}$ denotes the state of $R$ at the end of the previous iteration, with the initial settings $i^\star_0 = 0$ and $R^0 = R_{0, 0}$. It can be noticed that the condition $R^{j-1} \sim R_{i^\star_{j-1}, j}$ is maintained throughout the run. Also, it can be seen that the running time of each call to the procedure is dictated by the running time of its internal calls to the GetMin procedure (as there are $O(1)$ additional operations per call to GetMin). In each call to GetMin either the index $i$ or the index $j$ used in the query strictly increases with respect to the previous call, and therefore there are overall at most $2n$ calls to GetMin throughout the run. As shown in~\cite{lee2007simple}, the overall running time of all GetMin queries is $O(n)$.


\subsubsection{Type 2}
In this section we consider a different set of restrictions over the sequence of functions $g_j$. 
A series of functions $g_1, g_2, \ldots, g_n$ is of \emph{Type 2} if for every $j$ there exists some constant $c_j$ such that for every $0 \leq i < j-1$, $g_j(i) = g_{j-1}(i) + c_j$, and $g_j(j-1) = c_j$. For convenience, we will write $g(i) \equiv g_i(0)$, define that $g(0) = 0$, and assume that querying the minimum or maximum values in an empty set of values yield $\infty$ or $-\infty$ values, respectively..

We next assume a function $f$ and a Type 2 function series $g_1, g_2, \ldots, g_n$ are given, where the function $g$ is implied from the latter series. 

\begin{claim}
\label{clm:type_2}
	For every $0 < j \leq n$ and every $0 \leq i < j$, $g_j(i) = g(j) - g(i)$.
\end{claim} 

\begin{proof}
	For $j=1$ and $i=0$, we have by definition that $g_1(0) = g_1(0) - 0 = g(1) - g(0)$. 
	Assuming inductively the claim holds for every $j' < j$, we show it holds for $j$ too. Let $0 \leq i < j$. Then,
	$g_j(i) \stackrel{\text{Type 2}}{=} g_{j-1}(i) + c_j \stackrel{\text{induction}}{=} g(j-1) - g(i) + c_j \stackrel{\text{Type 2}}{=} g(j) - g(i)$.
\end{proof}

Consider the expression $\max\left\{f(i), g_j(i)\right\} \stackrel{\text{Clm~\ref{clm:type_2}}}{=} \max\left\{f(i), g(j) - g(i)\right\}$ for some $0 \leq i < j$. Clearly, $\max\left\{f(i), g_j(i)\right\} = f(i)$ when $g(j) \leq f(i) + g(i)$ and $\max\left\{f(i), g_j(i)\right\} = g_j(i) = g(j) - g(i)$ when $g(j) \geq f(i) + g(i)$. Denote $f^j = \hspace{-.5em}\min\limits_{{\tiny\begin{array}{c}
		0 \leq i < j, \\
		g(j) \leq f(i) + g(i)
		\end{array}}} \hspace{-1em} f(i)$
and $g^j = \hspace{-2em}\max\limits_{{\tiny\begin{array}{c}
		0 \leq i < j, \\
		g(j) \geq f(i) + g(i)
		\end{array}}} \hspace{-1em} g(i)$. Equation~\ref{eq:MM} can now be rewritten for the Type 2 scenario as follows:

\begin{equation}
\label{eq:MM2} 
	\begin{array}{rcl}
		\text{MM}(f, g_j, j) & = & \min\left\{
			\hspace{-.5em}\min\limits_{{\tiny\begin{array}{c}
				0 \leq i < j, \\
				g(j) \leq f(i) + g(i)
			\end{array}}} \hspace{-1em} \max\{f(i), g_j(i)\},
			\min\limits_{{\tiny \begin{array}{c}
				0 \leq i < j, \\
				g(j) \geq f(i) + g(i)
			\end{array}}} \hspace{-1em} \max\{f(i), g_j(i)\}
		\right\} \\
		& = & \min\left\{
			\hspace{-.5em}\min\limits_{{\tiny \begin{array}{c}
				0 \leq i < j, \\
				g(j) \leq f(i) + g(i)
				\end{array}}} \hspace{-1em} f(i), \ 
			g(j) - \hspace{-2em}\max\limits_{{\tiny\begin{array}{c}
				0 \leq i < j, \\
				g(j) \geq f(i) + g(i)
				\end{array}}} \hspace{-1em} g(i)
		\right\} \\
		& = & \min\left\{f^j, g(j) - g^j\right\}.
	\end{array}
\end{equation}

In order to compute the values $f^j$ and $g^j$ appearing at right-hand side of Equation~\ref{eq:MM2}, we next describe two data structures $F$ and $G$, that given $g(j)$ will allow the efficient retrievals of these values.
These two data structures will be implemented using \emph{sorted sets}.

A sorted set $S$ is a set of elements form $(k, v)$, where $k$ and $v$ are respectively referred to as the \emph{key} and \emph{value} of an element. We assume here the keys of $S$ are unique, and there is a total order "$\leq$" which is defined over the domain of keys.
In addition, the following operations are supported: 
\begin{enumerate}
	\item Find$(S, x)$ / FindPrev$(S, x)$ return an element $(k, v)$ in $S$ such that $x \leq k$ / $x > k$  and $k$ is minimal / maximal with respect to the order over the keys (or NULL if no such element exists), respectively;
%	\item FindPrev$(S, y)$ returns an element $s = (x, v)$ in $S$ such that $y > x$ and $x$ is maximal with respect to the order over the keys; % or NULL if $x \leq x'$ for every key $x'$ in $S$.
	\item Insert$(S, k, v)$ inserts an element $(k, v)$ into $S$, replacing if necessary an element $(k, v')$ with identical key if such an element exists in $S$;
	\item Min$(S)$ returns the minimal key in $S$.
\end{enumerate}

A standard efficient implementation for such a sorted set would be by using RB-trees [TODO: citations]. Such a data structure supports all of the above operations in $O(\log |S|)$ running time.

The $F$ sorted set is designed to compute values of the form $f^j$.
Given an index $j$, we will say that \emph{$F$ is valid for $x$} if the result of Find$(F, x)$ is a pair $(k, v)$ such that $v = \hspace{-.5em}\min\limits_{{\tiny \begin{array}{c}
		0 \leq i < j, \\
		x \leq f(i) + g(i)
		\end{array}}} \hspace{-1em} f(i)$.
The following two invariants will be used to describe the state of $F$ during the algorithm's run:

\paragraph{The $j$-invariant for $F$:}
$|F| = O(j)$, and $F$ is valid for any number $x$.

\paragraph{The relaxed $j$-invariant for $F$ and $(k, v)$:}
$|F| = O(j)$, $F$ is valid for any number $x$ such that $k \leq x$ or Find$(F, x) = (k_x, v_x)$ and $v_x < v$.
\bigskip

[TODO: write the symmetric text to describe $G$.]

Initializing the sets $F$ and $G$ so they would admit the $0$-invariant is simply creating a set $F$ with the single element $(\infty, \infty)$ and a set $G$ with the single element $(-\infty, -\infty)$.
Let $F$ and $G$ admit the $j$-invariant for some $j > 0$. 
Consider the values $(k_F, v_f)$ and $(k_G, v_G)$ returned from executing Find$(F, g(j))$ and FindPrev$(G, g(j))$. From the $j$-invariant,
$$
v_F = \hspace{-1em}\min\limits_{{\tiny \begin{array}{c}
		0 \leq i < j, \\
		g(j) \leq f(i) + g(i)
		\end{array}}} \hspace{-1em} f(i) = f^j, \ 
v_G = \hspace{-1em}\max\limits_{{\tiny \begin{array}{c}
		0 \leq i < j, \\
		g(j) \geq f(i) + g(i),
		\end{array}}} \hspace{-1em} g(i) = g^j
$$ 
and so from Equation~\ref{eq:MM2} we have that $\text{MM}(f, g_j, j) = \min\{v_F, g(j) - v_G\}$.



In order to update $F$ and $G$ so they would sustain the $(j+1)$-invariant we do the following. For $F$, denote by $F^j$ the set which sustains the $j$ invariant, from which we show how to construct a set $F^{j+1}$ that sustains the $(j+1)$ invariant. In the latter set we need to consider a new possible value $f(j)$, which might be the value in some element returned due to a query of the form Find$(F^{j+1}, x)$. By definition, for $f(j)$ to be the returned element value, it must be that $f(j) + g(j) \geq x$. In particular, for every $y$ such that $f(j) + g(j) < y$, $f(j)$ should not be considered, and so the returned values from Find$(F^{j+1}, y)$ and Find$(F^{j}, y)$ should be te same. In addition, if Find$(F^{j}, x) = (k, v)$ such that $v < f(j)$, then clearly Find$(F^{j+1}, x)$ should also return an element whose value is $v$. Thus, $F^j$ admits the relaxed $(j+1)$-invariant for $(f(j) + g(j), f(j))$.

The following algorithm shows how given a data structure $F$ that maintains the $j$-invariant, it is updated to maintain the $(j+1)$-invariant.

\begin{algorithm}
	\Precondition{$F$ maintains the $j$-invariant}
	%	\tcp{Updating the data structures:}
	denote $x = f(j) + g(j)$, and let $(k, v) \gets \text{Find}(F, x)$\;
	\Condition{$F$ maintains the relaxed $(j+1)$-invariant for $(x^+, f(j))$}
	\If{$f(j) \leq v$}{
		Insert$(F, x, f(j))$\;
		\Condition{$F$ maintains the relaxed $(j+1)$-invariant for $(x, f(j))$}
		\If{$x > \text{Min}(S)$}{
			$(k, v) \gets \text{FindPrev}(F, x)$\;
			\LoopInv{$F$ maintains the relaxed $(j+1)$-invariant for $(k^+, f(j))$}
			\While{$f(j) \leq v$}{
				Remove$(F, k)$\;
				\Condition{$F$ maintains the relaxed $(j+1)$-invariant for $(k, f(j))$}
				\lIf{$x > \text{Min}(S)$}{$(k, v) \gets \text{FindPrev}(F, x)$}
				\lElse{\Break}
			}
		}
	}
	\Postcondition{$F$ maintains the $(j+1)$-invariant}
	\Return{$F$}\;
	\caption{Update-F$(F, f(j), g(j))$}
	\label{algo:MM2}
\end{algorithm}



\begin{algorithm}
	\Precondition{$S$ sustains the $S$-invariant for $j-1$}
%	\tcp{Updating the data structures:}
	set $x \gets f(j-1) + g_j(0)$\;
	let $s' \gets \text{Find}(S, x)$\;
	if $s'$ is not NULL, it is of the form $s' = (x', (k', F', G'))$. For the case where $s'$ is NULL, define $F'$
	\If{$s' = \text{NULL}$}{
		set $F \gets \min\left\{f(j-1), F'\right\}$ if $i < j-1$, otherwise $F_{j-1} \gets f(j-1)$\; 
		set $G_{j-1} \gets \max\left\{g_j(j-1), G_{K_i-1}\right\}$ if $i > 0$, otherwise $G_{j-1} \gets g_j(j-1)$\; 
	}
	\Else{
		set $F \gets \min\left\{f(j-1), F'\right\}$\; 
		set $G \gets \max\left\{g_j(0), G'\right\}$\; 
	}
	Insert$(S, x, (j-1, F, G))$\; 
	\Condition{$S$ sustains the $S$-invariant for $j$}
	\Return{$\min\{F, g_j(0) - G\}$}\;
	\caption{MM2$(f^d[\cdot], g^d[\cdot], d[\cdot], g_{j-1}(0), c_j, j)$}
	\label{algo:MM2}
\end{algorithm}
